{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rounds = [1,2,3]\n",
    "test_round = [4]\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in train_rounds:\n",
    "    X_train.append(np.load('hand_activities_data/rounds/round{}_features_X.npy'.format(i)))\n",
    "    y_train.append(np.load('hand_activities_data/rounds/round{}_features_labels.npy'.format(i)))\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "X_test = np.load('hand_activities_data/rounds/round{}_features_X.npy'.format(4))\n",
    "y_test = np.load('hand_activities_data/rounds/round{}_features_labels.npy'.format(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "y_train = ohe.fit_transform(y_train.reshape((-1,1))).toarray()\n",
    "y_test = ohe.transform(y_test.reshape((-1,1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_size = 256\n",
    "width = 48\n",
    "num_channels = 3\n",
    "num_classes = 25\n",
    "\n",
    "X_train = X_train.reshape((-1, fft_size, width, num_channels))\n",
    "X_test = X_test.reshape((-1, fft_size, width, num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93436, 64, 48, 3) (93436, 25)\n",
      "(31203, 64, 48, 3) (31203, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 8\n",
    "X_train = X_train[:,0:fft_size//scale_factor,:,:]\n",
    "X_test = X_test[:,0:fft_size//scale_factor,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape = (fft_size//scale_factor, width, num_channels))\n",
    "\n",
    "# Block-1\n",
    "x = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\")(inp)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "\n",
    "# Block-2\n",
    "x = Conv2D(filters=128, kernel_size=(3,3), padding=\"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "\n",
    "# Block-3\n",
    "x = Conv2D(filters=256, kernel_size=(3,3), padding=\"valid\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "\n",
    "# # Block-4\n",
    "# x = Conv2D(filters=512, kernel_size=(3,3), padding=\"valid\")(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = MaxPooling2D(pool_size=(2,2),strides=(2,2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Classifier\n",
    "x = Dense(units=2000)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dense(units=500)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "out = Dense(units=num_classes, activation='softmax')(x)\n",
    "model = Model(inp, out, name='hand_activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"hand_activities\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 22, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 22, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 11, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 5, 9, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 5, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              4098000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2000)              8000      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                12525     \n",
      "=================================================================\n",
      "Total params: 5,493,633\n",
      "Trainable params: 5,487,737\n",
      "Non-trainable params: 5,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = load_model('model_main.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_16\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_{}'.format(fft_size//2//scale_factor)\n",
    "print(model_name)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model_checkpoint = ModelCheckpoint(filepath='checkpoints/{}.h5'.format(model_name), \n",
    "                                   monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1, patience=12)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_lr=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1460/1460 [==============================] - ETA: 0s - loss: 0.8601 - accuracy: 0.6983\n",
      "Epoch 00001: val_loss improved from inf to 1.21039, saving model to checkpoints/model_16.h5\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.8601 - accuracy: 0.6983 - val_loss: 1.2104 - val_accuracy: 0.6314\n",
      "Epoch 2/100\n",
      "1457/1460 [============================>.] - ETA: 0s - loss: 0.3971 - accuracy: 0.8544\n",
      "Epoch 00002: val_loss did not improve from 1.21039\n",
      "1460/1460 [==============================] - 12s 8ms/step - loss: 0.3970 - accuracy: 0.8544 - val_loss: 1.4353 - val_accuracy: 0.6712\n",
      "Epoch 3/100\n",
      "1455/1460 [============================>.] - ETA: 0s - loss: 0.2580 - accuracy: 0.9053\n",
      "Epoch 00003: val_loss did not improve from 1.21039\n",
      "1460/1460 [==============================] - 12s 8ms/step - loss: 0.2578 - accuracy: 0.9054 - val_loss: 1.2173 - val_accuracy: 0.6856\n",
      "Epoch 4/100\n",
      "1457/1460 [============================>.] - ETA: 0s - loss: 0.1862 - accuracy: 0.9313\n",
      "Epoch 00004: val_loss did not improve from 1.21039\n",
      "1460/1460 [==============================] - 12s 8ms/step - loss: 0.1861 - accuracy: 0.9313 - val_loss: 1.2456 - val_accuracy: 0.7260\n",
      "Epoch 5/100\n",
      "1457/1460 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9489\n",
      "Epoch 00005: val_loss did not improve from 1.21039\n",
      "1460/1460 [==============================] - 12s 8ms/step - loss: 0.1395 - accuracy: 0.9489 - val_loss: 1.7166 - val_accuracy: 0.6375\n",
      "Epoch 6/100\n",
      "1456/1460 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9613\n",
      "Epoch 00006: val_loss did not improve from 1.21039\n",
      "1460/1460 [==============================] - 12s 8ms/step - loss: 0.1072 - accuracy: 0.9613 - val_loss: 2.0478 - val_accuracy: 0.6369\n",
      "Epoch 7/100\n",
      "1454/1460 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9672\n",
      "Epoch 00007: val_loss did not improve from 1.21039\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0911 - accuracy: 0.9672 - val_loss: 3.3422 - val_accuracy: 0.5533\n",
      "Epoch 8/100\n",
      "1459/1460 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9730\n",
      "Epoch 00008: val_loss did not improve from 1.21039\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0752 - accuracy: 0.9730 - val_loss: 2.5852 - val_accuracy: 0.5790\n",
      "Epoch 9/100\n",
      "1455/1460 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9905\n",
      "Epoch 00009: val_loss improved from 1.21039 to 0.91573, saving model to checkpoints/model_16.h5\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.9157 - val_accuracy: 0.8209\n",
      "Epoch 10/100\n",
      "1460/1460 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9936\n",
      "Epoch 00010: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 12s 9ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.9415 - val_accuracy: 0.8228\n",
      "Epoch 11/100\n",
      "1456/1460 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9948\n",
      "Epoch 00011: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 1.2872 - val_accuracy: 0.7757\n",
      "Epoch 12/100\n",
      "1456/1460 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9955\n",
      "Epoch 00012: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.9400 - val_accuracy: 0.8388\n",
      "Epoch 13/100\n",
      "1454/1460 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 00013: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 1.0031 - val_accuracy: 0.8206\n",
      "Epoch 14/100\n",
      "1458/1460 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch 00014: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.9758 - val_accuracy: 0.8346\n",
      "Epoch 15/100\n",
      "1456/1460 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 00015: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 1.0037 - val_accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "1458/1460 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00016: val_loss did not improve from 0.91573\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 1.0932 - val_accuracy: 0.8230\n",
      "Epoch 17/100\n",
      "1456/1460 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9977\n",
      "Epoch 00017: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 1.0780 - val_accuracy: 0.8203\n",
      "Epoch 18/100\n",
      "1459/1460 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00018: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 1.1512 - val_accuracy: 0.8117\n",
      "Epoch 19/100\n",
      "1454/1460 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 00019: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.1086 - val_accuracy: 0.8245\n",
      "Epoch 20/100\n",
      "1459/1460 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00020: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 1.1231 - val_accuracy: 0.8216\n",
      "Epoch 21/100\n",
      "1454/1460 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 00021: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.0761 - val_accuracy: 0.8373\n",
      "Epoch 22/100\n",
      "1457/1460 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00022: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 1.4091 - val_accuracy: 0.7906\n",
      "Epoch 23/100\n",
      "1459/1460 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 00023: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.1315 - val_accuracy: 0.8242\n",
      "Epoch 24/100\n",
      "1458/1460 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 00024: val_loss did not improve from 0.91573\n",
      "1460/1460 [==============================] - 13s 9ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.1159 - val_accuracy: 0.8345\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    shuffle=True, \n",
    "                    callbacks=[model_checkpoint, early_stopping, reduce_lr],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('checkpoints/{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_16\n",
      "976/976 [==============================] - 2s 2ms/step - loss: 0.9157 - accuracy: 0.8209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9157345294952393, 0.8208826184272766]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_name)\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
