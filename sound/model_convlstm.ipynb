{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1601570430822,
     "user": {
      "displayName": "Dhruv Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPErif29dJTpYr10Kx4Olz-3fBzlJHUINscaF57A=s64",
      "userId": "04055500837937310636"
     },
     "user_tz": -330
    },
    "id": "YxPWN60xnHWF",
    "outputId": "c229db07-8588-4b5b-c3d6-2bb66bf94d78"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 10625,
     "status": "ok",
     "timestamp": 1601570503201,
     "user": {
      "displayName": "Dhruv Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPErif29dJTpYr10Kx4Olz-3fBzlJHUINscaF57A=s64",
      "userId": "04055500837937310636"
     },
     "user_tz": -330
    },
    "id": "EVhv2x0omPUX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import vggish_params\n",
    "import vggish_keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import Accuracy, Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from statistics import mode\n",
    "from tqdm import tqdm, trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 1000\n",
    "sec = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 182202,
     "status": "ok",
     "timestamp": 1601570827794,
     "user": {
      "displayName": "Dhruv Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjPErif29dJTpYr10Kx4Olz-3fBzlJHUINscaF57A=s64",
      "userId": "04055500837937310636"
     },
     "user_tz": -330
    },
    "id": "Y4WQOp9S_tP2"
   },
   "outputs": [],
   "source": [
    "X_train = np.load('temporal_data/{}sec/features_train_{}.npy'.format(sec, sfreq), allow_pickle=True)\n",
    "y_train = np.load('temporal_data/{}sec/labels_train_{}.npy'.format(sec, sfreq), allow_pickle=True)\n",
    "\n",
    "speech_index = 23\n",
    "\n",
    "X_train = list(X_train)\n",
    "y_train = list(y_train)\n",
    "del X_train[speech_index], y_train[speech_index]\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)    \n",
    "\n",
    "valid_idx = []\n",
    "for i in range(len(X_train)):\n",
    "    if len(X_train[i] == 3):\n",
    "        valid_idx.append(i)\n",
    "    elif len(X_train[i] != 0):\n",
    "        print('ghotala! @ {}'.format(i))\n",
    "\n",
    "X_train = X_train[valid_idx]\n",
    "y_train = y_train[valid_idx]\n",
    "\n",
    "shuffled_idx = np.arange(len(X_train))\n",
    "np.random.shuffle(shuffled_idx)\n",
    "\n",
    "X_train = X_train[shuffled_idx]\n",
    "y_train = y_train[shuffled_idx]\n",
    "\n",
    "# X_train = np.concatenate(X_train)\n",
    "# y_train = np.concatenate(y_train)\n",
    "\n",
    "NUM_BANDS = X_train[0].shape[1]\n",
    "NUM_FRAMES = X_train[0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9cecf58370>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(X_train[1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232733,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "id": "d5lV09hPoyUA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alarm-clock': 2.123088852399197,\n",
       " 'baby-cry': 1.332880893882904,\n",
       " 'blender': 2.856986778949436,\n",
       " 'car-horn': 13.006930084390543,\n",
       " 'cat-meow': 5.060073053006914,\n",
       " 'chopping': 3.120247224754652,\n",
       " 'cooking': 0.6642340557911741,\n",
       " 'cough': 4.257440775633404,\n",
       " 'dishwasher': 1.2547335619244786,\n",
       " 'dog-bark': 0.7516414594051668,\n",
       " 'door': 2.6321009714886734,\n",
       " 'doorbell': 6.344091590568352,\n",
       " 'drill': 1.2015684776267355,\n",
       " 'engine': 0.31368339048111965,\n",
       " 'flush': 1.1078514442392278,\n",
       " 'hair-dryer': 1.3145415007483974,\n",
       " 'hammer': 0.7489758154054098,\n",
       " 'hazard-alarm': 0.3492743117930524,\n",
       " 'knock': 3.6445394468978045,\n",
       " 'laugh': 2.52208543748239,\n",
       " 'microwave': 0.938299527893016,\n",
       " 'phone-ring': 1.1121502026148788,\n",
       " 'saw': 1.388696290373588,\n",
       " 'shaver': 1.9144264938141615,\n",
       " 'snore': 3.010231006027369,\n",
       " 'toothbrush': 4.160329633006203,\n",
       " 'typing': 0.479321260351727,\n",
       " 'vacuum': 0.6073313048334317,\n",
       " 'water-running': 0.2292019152929961}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            np.unique(np.concatenate(y_train)),\n",
    "                                            np.concatenate(y_train))\n",
    "class_weights = dict(enumerate(weights))\n",
    "class_name_weights = {np.unique(np.concatenate(y_train))[key]:class_weights[key] for key in class_weights.keys()}\n",
    "class_name_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "S_H-1vfmo2OO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12224/12224 [00:02<00:00, 5688.36it/s]\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(np.concatenate(y_train).reshape((-1,1)))\n",
    "\n",
    "NUM_CLASSES = len(weights)\n",
    "NUM_FILES = len(y_train)\n",
    "\n",
    "y_ohe = []\n",
    "for i in tqdm(range(NUM_FILES)):\n",
    "    file_ohe = ohe.transform(np.array(y_train[i]).reshape((-1,1))).toarray().reshape((-1, NUM_CLASSES))\n",
    "    y_ohe.append(file_ohe)              \n",
    "    X_train[i] = X_train[i].reshape((-1, NUM_BANDS, NUM_FRAMES, 1))\n",
    "    \n",
    "y_train = np.array(y_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 21, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1176/1176 [00:00<00:00, 5628.49it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('temporal_data/{}sec/features_test_{}.npy'.format(sec, sfreq), allow_pickle=True)\n",
    "y_test = np.load('temporal_data/{}sec/labels_test_{}.npy'.format(sec, sfreq), allow_pickle=True)\n",
    "\n",
    "X_test = list(X_test)\n",
    "y_test = list(y_test)\n",
    "del X_test[speech_index], y_test[speech_index]\n",
    "\n",
    "X_test = np.concatenate(X_test)\n",
    "y_test = np.concatenate(y_test)      \n",
    "\n",
    "valid_idx = []\n",
    "for i in range(len(X_test)):\n",
    "    if len(X_test[i] == 3):\n",
    "        valid_idx.append(i)\n",
    "    elif len(X_test[i] != 0):\n",
    "        print('ghotala! @ {}'.format(i))\n",
    "    \n",
    "X_test = X_test[valid_idx]\n",
    "y_test = y_test[valid_idx]\n",
    "   \n",
    "shuffled_idx = np.arange(len(X_test))\n",
    "np.random.shuffle(shuffled_idx)\n",
    "\n",
    "X_test = X_test[shuffled_idx]\n",
    "y_test = y_test[shuffled_idx]\n",
    "\n",
    "# X_test = np.concatenate(X_test)\n",
    "# y_test = np.concatenate(y_test)\n",
    "\n",
    "NUM_TEST_FILES = len(y_test)\n",
    "\n",
    "y_ohe = []\n",
    "for i in tqdm(range(NUM_TEST_FILES)):\n",
    "    file_ohe = ohe.transform(np.array(y_test[i]).reshape((-1,1))).toarray().reshape((-1, NUM_CLASSES))\n",
    "    y_ohe.append(file_ohe)              \n",
    "    X_test[i] = X_test[i].reshape((-1, NUM_BANDS, NUM_FRAMES, 1))\n",
    "\n",
    "y_test = np.array(y_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape (6, 64, 21, 1)\n",
      "X test  shape (1, 64, 21, 1)\n",
      "y train shape (6, 29)\n",
      "y test  shape (1, 29)\n"
     ]
    }
   ],
   "source": [
    "idx = 13\n",
    "print('X train shape {}'.format(X_train[idx].shape))\n",
    "print('X test  shape {}'.format(X_test[idx].shape))\n",
    "print('y train shape {}'.format(y_train[idx].shape))\n",
    "print('y test  shape {}'.format(y_test[idx].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(1, 64, 21, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (1, 64, 21, 64)           640       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (1, 32, 10, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (1, 32, 10, 128)          73856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (1, 16, 5, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (1, 16, 5, 256)           295168    \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (1, 16, 5, 256)           590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (1, 8, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (1, 8, 2, 512)            1180160   \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (1, 8, 2, 512)            2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (1, 4, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (1, 4096)                 0         \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (1, 1, 4096)              0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1, 256)                  4457472   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (1, 128)                  32896     \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (1, 29)                   3741      \n",
      "=================================================================\n",
      "Total params: 8,993,821\n",
      "Trainable params: 8,993,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, LSTM, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "# Input\n",
    "input_shape = (NUM_BANDS, NUM_FRAMES, 1)\n",
    "batch_input_shape = (1, NUM_BANDS, NUM_FRAMES, 1)\n",
    "img_input = Input(batch_input_shape = batch_input_shape)\n",
    "\n",
    "# Block 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1')(img_input)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "# Block 4\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "x = MaxPooling2D((2, 1), strides=(2, 1), name='pool4')(x)\n",
    "\n",
    "x = Flatten(name='flatten')(x)\n",
    "\n",
    "# LSTM\n",
    "x = Reshape((1, -1))(x)\n",
    "x = LSTM(units = 256, stateful=True, name='lstm')(x)\n",
    "\n",
    "# # Block fc\n",
    "# x = Dense(1024, activation='relu', name='fc1_2')(x)\n",
    "# x = Dropout(0.4)(x)\n",
    "x = Dense(128,  activation='relu', name='fc2')(x)\n",
    "# x = Dropout(0.4)(x)\n",
    "x = Dense(NUM_CLASSES, activation='sigmoid', name='prediction')(x)\n",
    "model = Model(img_input, x, name='model')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'convlstm_{}_{}'.format(sec, sfreq)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.load_weights('checkpoints/model_{}.h5'.format(sfreq))\n",
    "\n",
    "checkpoint = ModelCheckpoint('checkpoints/{}.h5'.format(MODEL_NAME), monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "earlystopping = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=10, verbose=1, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 11, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: Train: 100%|██████████| 12224/12224 [1:20:21<00:00,  2.54it/s, loss=0.157, accuracy=0.125]  \n",
      "epoch 1: Test: 100%|██████████| 1176/1176 [02:10<00:00,  9.01it/s, loss=0.159, accuracy=0.111]\n",
      "epoch 2: Train:   0%|          | 0/12224 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy improved from 0.0 to 0.11084204167127609. saving model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: Train: 100%|██████████| 12224/12224 [1:17:03<00:00,  2.64it/s, loss=0.159, accuracy=0.117]  \n",
      "epoch 2: Test: 100%|██████████| 1176/1176 [02:09<00:00,  9.08it/s, loss=0.159, accuracy=0.11] \n",
      "epoch 3: Train:   0%|          | 0/12224 [00:00<?, ?it/s, loss=0.159, accuracy=0.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: Train: 100%|██████████| 12224/12224 [1:16:41<00:00,  2.66it/s, loss=0.159, accuracy=0.114]  \n",
      "epoch 3: Test: 100%|██████████| 1176/1176 [02:08<00:00,  9.14it/s, loss=0.16, accuracy=0.11] \n",
      "epoch 4: Train:   0%|          | 0/12224 [00:00<?, ?it/s, loss=0.16, accuracy=0.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: Train: 100%|██████████| 12224/12224 [1:16:48<00:00,  2.65it/s, loss=0.16, accuracy=0.113]   \n",
      "epoch 4: Test: 100%|██████████| 1176/1176 [02:08<00:00,  9.12it/s, loss=0.16, accuracy=0.11]\n",
      "epoch 5: Train:   0%|          | 0/12224 [00:00<?, ?it/s, loss=0.16, accuracy=0.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: Train: 100%|██████████| 12224/12224 [1:16:32<00:00,  2.66it/s, loss=0.16, accuracy=0.112]   \n",
      "epoch 5: Test: 100%|██████████| 1176/1176 [02:09<00:00,  9.05it/s, loss=0.16, accuracy=0.11]\n",
      "epoch 6: Train:   0%|          | 0/12224 [00:00<?, ?it/s, loss=0.16, accuracy=0.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: Train:  57%|█████▋    | 6986/12224 [43:17<32:27,  2.69it/s, loss=0.159, accuracy=0.111]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-1636e20a1d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'train': [],\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "max_acc = 0.0\n",
    "for epoch in range(10):\n",
    "    \n",
    "    # Training\n",
    "    num_batches = len(X_train) \n",
    "    t = trange(num_batches, desc='epoch {}: Train'.format(epoch+1))\n",
    "    for i in t:\n",
    "        X_batch = X_train[i]\n",
    "        y_batch = y_train[i]\n",
    "        num_samples = len(X_batch)\n",
    "        for j in range(num_samples):\n",
    "            X = X_batch[j:j+1]\n",
    "            y = y_batch[j:j+1]\n",
    "            metrics = model.train_on_batch(X, y, class_weight=class_weights, reset_metrics=False, return_dict=True)\n",
    "        lstm = model.get_layer('lstm')\n",
    "        lstm.reset_states()\n",
    "        t.set_postfix(metrics)\n",
    "    history['train'].append(metrics)\n",
    "    \n",
    "    # Testing\n",
    "    num_batches = len(X_test) \n",
    "    t = trange(num_batches, desc='epoch {}: Test'.format(epoch+1))\n",
    "    for i in t:\n",
    "        X_batch = X_test[i]\n",
    "        y_batch = y_test[i]\n",
    "        num_samples = len(X_batch)\n",
    "        for j in range(num_samples):\n",
    "            X = X_batch[j:j+1]\n",
    "            y = y_batch[j:j+1]\n",
    "            metrics = model.test_on_batch(X, y, reset_metrics=False, return_dict=True)\n",
    "        lstm = model.get_layer('lstm')\n",
    "        lstm.reset_states()\n",
    "        t.set_postfix(metrics)\n",
    "    history['test'].append(metrics)\n",
    "    \n",
    "    if max_acc < metrics['accuracy']:\n",
    "        print('val accuracy improved from {} to {}. saving model...'.format(max_acc, metrics['accuracy']))\n",
    "        max_acc = metrics['accuracy']\n",
    "        model.save('checkpoints/{}.h5'.format(MODEL_NAME))\n",
    "        \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for file in range(NUM_FILES):\n",
    "        NUM_FRAMES = X_train[file].shape[0]\n",
    "        for frame in range(NUM_FRAMES):\n",
    "        X_file_train = X_train[file][frame:frame+1]\n",
    "        y_file_train = y_train[file][frame:frame+1]\n",
    "        history = model.fit(X_file_train, y_file_train, epochs=1, batch_size=1, \n",
    "                    class_weight=class_weights, callbacks= [checkpoint, earlystopping, reducelr], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint!\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('checkpoints/{}.h5'.format(MODEL_NAME))\n",
    "print('Loaded best checkpoint!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convlstm_2_1000'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = ohe.inverse_transform(y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {label: ohe.transform(np.array(label).reshape(-1,1)).toarray() for label in np.unique(labels_test)}\n",
    "\n",
    "contexts = {\n",
    "    'monolithic': ['alarm-clock', 'baby-cry', 'blender', 'car-horn', 'cat-meow',\n",
    "       'chopping', 'cooking', 'cough', 'dishwasher', 'dog-bark', 'door',\n",
    "       'doorbell', 'drill', 'engine', 'flush', 'hair-dryer', 'hammer',\n",
    "       'hazard-alarm', 'knock', 'laugh', 'microwave', 'phone-ring', 'saw',\n",
    "       'shaver', 'snore', 'speech', 'toothbrush', 'typing', 'vacuum',\n",
    "       'water-running'],\n",
    "    'bathroom': ['water-running', 'shaver', 'toothbrush', 'flush', 'hair-dryer'],\n",
    "    'kitchen': ['hazard-alarm', 'speech', 'chopping', 'water-running', 'microwave', 'blender', 'dishwasher', 'cooking'],\n",
    "    'bedroom': ['speech', 'baby-cry', 'cough', 'snore', 'alarm-clock'],\n",
    "    'office': ['phone-ring', 'speech', 'cough', 'door', 'knock', 'typing'],\n",
    "    'entrance': ['speech', 'door', 'knock', 'doorbell', 'laugh'],\n",
    "    'workshop': ['drill', 'hazard-alarm', 'speech', 'vacuum', 'hammer', 'saw'],\n",
    "    'outdoor': ['dog-bark', 'hazard-alarm', 'speech', 'car-horn', 'engine', 'cat-meow']\n",
    "}\n",
    "\n",
    "context_encoding = {}\n",
    "for context in contexts.keys():\n",
    "    context_encoding[context] = np.zeros((1,30))\n",
    "    for activity in contexts[context]:\n",
    "        context_encoding[context] += encoding[activity]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for context in contexts.keys():\n",
    "#     context = list(contexts.keys())[0]\n",
    "    valid_idx = [i for i, label in enumerate(labels_test) if label in contexts[context]]\n",
    "    valid_pred = pred[valid_idx]\n",
    "    valid_labels = labels_test[valid_idx]\n",
    "    valid_pred = np.argmax(valid_pred * context_encoding[context], axis=1)\n",
    "    valid_pred = [ohe.categories_[0][pr] for pr in valid_pred]\n",
    "    acc = accuracy_score(valid_labels, valid_pred)\n",
    "    f1 = f1_score(valid_labels, valid_pred, average='weighted')\n",
    "    conf_mat = confusion_matrix(valid_labels, valid_pred, normalize='true')\n",
    "    label_names = np.unique(valid_labels)\n",
    "    print('{},{},{},{},{}'.format(sfreq,context,acc,f1,sec))\n",
    "    # fig, ax = plt.subplots(figsize=(13,10))\n",
    "    # sns.heatmap(conf_mat, cmap='Blues', ax=ax, xticklabels=label_names, yticklabels=label_names, annot=False)\n",
    "    # ax.set_title('sFreq: {}, Context: {}, Acc: {}'.format(sfreq,context,acc))\n",
    "    # ax.set_xlabel('Predicted Label')\n",
    "    # ax.set_ylabel('True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12224"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File-Level Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bands = 64\n",
    "X_test = np.load('temporal_data/{}sec/features_test_{}.npy'.format(sec, sfreq), allow_pickle=True)\n",
    "y_test = np.load('temporal_data/{}sec/labels_test_{}.npy'.format(sec, sfreq), allow_pickle=True)\n",
    "\n",
    "X_test = np.concatenate(X_test)\n",
    "y_test = np.concatenate(y_test)    \n",
    "\n",
    "valid_idx = []\n",
    "for i in range(len(X_test)):\n",
    "    if len(X_test[i] == 3):\n",
    "        valid_idx.append(i)\n",
    "    elif len(X_test[i] != 0):\n",
    "        print('ghotala! @ {}'.format(i))\n",
    "\n",
    "X_test = X_test[valid_idx]\n",
    "y_test = y_test[valid_idx]\n",
    "\n",
    "X_test = [file.reshape((-1, NUM_BANDS, NUM_FRAMES, 1)) for file in X_test]\n",
    "y_test = [ohe.transform(np.array(file).reshape(-1,1)).toarray().reshape((-1, NUM_CLASSES)) for file in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('checkpoints/{}.h5'.format(MODEL_NAME))\n",
    "print('Loaded best checkpoint!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = np.array([ohe.inverse_transform(file).flatten() for file in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array([model.predict(file) for file in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_time = []\n",
    "for file in tqdm(X_test):\n",
    "    for i in range(len(file)):\n",
    "        frame = file[i:i+1]\n",
    "        st = time.time()\n",
    "        prediction = model.predict(frame)\n",
    "        en = time.time()\n",
    "        pred_time.append(en-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{},{}'.format(sfreq, np.mean(pred_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {label: ohe.transform(np.array(label).reshape(-1,1)).toarray() for label in np.unique(np.concatenate(labels_test).flatten())}\n",
    "\n",
    "contexts = {\n",
    "    'monolithic': ['alarm-clock', 'baby-cry', 'blender', 'car-horn', 'cat-meow',\n",
    "       'chopping', 'cooking', 'cough', 'dishwasher', 'dog-bark', 'door',\n",
    "       'doorbell', 'drill', 'engine', 'flush', 'hair-dryer', 'hammer',\n",
    "       'hazard-alarm', 'knock', 'laugh', 'microwave', 'phone-ring', 'saw',\n",
    "       'shaver', 'snore', 'speech', 'toothbrush', 'typing', 'vacuum',\n",
    "       'water-running'],\n",
    "    'bathroom': ['water-running', 'shaver', 'toothbrush', 'flush', 'hair-dryer'],\n",
    "    'kitchen': ['hazard-alarm', 'speech', 'chopping', 'water-running', 'microwave', 'blender', 'dishwasher', 'cooking'],\n",
    "    'bedroom': ['speech', 'baby-cry', 'cough', 'snore', 'alarm-clock'],\n",
    "    'office': ['phone-ring', 'speech', 'cough', 'door', 'knock', 'typing'],\n",
    "    'entrance': ['speech', 'door', 'knock', 'doorbell', 'laugh'],\n",
    "    'workshop': ['drill', 'hazard-alarm', 'speech', 'vacuum', 'hammer', 'saw'],\n",
    "    'outdoor': ['dog-bark', 'hazard-alarm', 'speech', 'car-horn', 'engine', 'cat-meow']\n",
    "}\n",
    "\n",
    "context_encoding = {}\n",
    "for context in contexts.keys():\n",
    "    context_encoding[context] = np.zeros((1,30))\n",
    "    for activity in contexts[context]:\n",
    "        context_encoding[context] += encoding[activity]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for context in contexts.keys():\n",
    "    valid_idx = [i for i, label in enumerate(labels_test) if label[0] in contexts[context]]\n",
    "    valid_pred = pred[valid_idx]\n",
    "    valid_labels = labels_test[valid_idx]\n",
    "    valid_pred = [np.argmax(file * context_encoding[context], axis=1) for file in valid_pred]\n",
    "    # Transform to per file level labels\n",
    "    valid_pred = [ohe.categories_[0][mode(file)] for file in valid_pred]\n",
    "    valid_labels = [file[0] for file in valid_labels]\n",
    "    acc = accuracy_score(valid_labels, valid_pred)\n",
    "    f1 = f1_score(valid_labels, valid_pred, average='weighted')\n",
    "    conf_mat = confusion_matrix(valid_labels, valid_pred, normalize='true')\n",
    "    label_names = np.unique(valid_labels)\n",
    "    print('{},{},{},{}'.format(sfreq, context, acc, f1))\n",
    "    fig, ax = plt.subplots(figsize=(13,10))\n",
    "    sns.heatmap(conf_mat, cmap='Blues', ax=ax, xticklabels=label_names, yticklabels=label_names, annot=False)\n",
    "    ax.set_title('sFreq: {}, Context: {}, Acc: {}'.format(sfreq,context,acc))\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOZ3nl0I+mVkmJRBp9GYBH+",
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
